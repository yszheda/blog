<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: linux | My Octopress Blog]]></title>
  <link href="http://yszheda.github.io/blog/blog/categories/linux/atom.xml" rel="self"/>
  <link href="http://yszheda.github.io/blog/"/>
  <updated>2020-05-06T20:50:53+08:00</updated>
  <id>http://yszheda.github.io/blog/</id>
  <author>
    <name><![CDATA[Your Name]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[OpenResty折腾记]]></title>
    <link href="http://yszheda.github.io/blog/blog/2016/07/24/my-first-openresty-journey/"/>
    <updated>2016-07-24T11:22:00+08:00</updated>
    <id>http://yszheda.github.io/blog/blog/2016/07/24/my-first-openresty-journey</id>
    <content type="html"><![CDATA[<p>前面几篇文章稍稍提到本渣最近接手了一个server端开发的活，这次就来碎碎念一下好了。虽然我们server端用<code>OpenResty</code>，和client端一样主要也是用<code>lua</code>开发，不过实在也不是本渣谦虚，本渣一个client端码农，肿么就被叫去写server端代码捏？<del>是因为组织上对本渣的信任。</del>是因为啊，我们server端想要实现战斗这块功能。而这块功能呢，恰好client端已经实现过。本渣嘛，又承担过不少战斗功能的开发工作。所以组织上说，既然你以前在client端挖过不少这种坑，那么server端的坑也由你来挖吧？于是本渣就<del>念了两句诗</del>接了这活。</p>

<p>本渣从一开始接手开始，就打定主意直接在server端重用client端的战斗功能代码。一方面是因为本渣很懒，已经实现过的轮子不想再造一遍；另一方面是因为我们client端的这块代码仍在迭代中，会不时上一些新类型的战斗玩法，如果server端再重新实现一遍，以后还得把client端新的改动也搬过来，这不仅不好维护，而且又是翻倍的工作量。最好就是把client端的战斗功能代码当做server端代码的一个submodule，client端有改动的话就直接pull下更新来使用。client端的这部分代码虽然也是<code>lua</code>写的，但要重用的话有个问题：我们client端用了<code>cocos2d-x</code>和<code>quick-x</code>，但server端只是个Web API Server，最好避免引入<code>cocos2d-x</code>和<code>quick-x</code>的<code>C++</code> API、以及<code>Node</code>之类的view（嗯，MVC的view）相关对象。好在最开始做战斗的大神设计得当，把战斗功能划分为战斗计算模块和战斗表现模块——前者计算出手先后、技能释放、buff和属性值改变等等，生成战报；后者再根据前者所生成的战报，播放相应的特效动画和人物动作——等到半年后本渣接手时，为了实现独立的战报播放功能，又把这块代码重构了，去掉了两个模块之间的耦合，所以战斗计算模块基本是独立于<code>cocos2d-x</code>和<code>quick-x</code>的<code>C++</code>代码、与view完全无关的纯<code>lua</code>实现。本渣只需要再补上<code>quick-x</code>中一些如<code>math.round</code>的全局函数的定义，很快就能在server端跑通了，但是新的问题又来了：</p>

<ol>
<li><p>有一定概率出现全局函数没有定义的错误，但是在代码里，这些全局函数在定义后并没有被修改。</p></li>
<li><p>在用<code>nginx</code> start或reload的方式创建新的<code>nginx</code> worker进程后，第一次访问有很大概率会失败。</p></li>
</ol>


<p>由于本渣是第一次接触<code>OpenResty</code>，这些问题一开始让本渣丈二和尚摸不着头脑，后来才渐渐理清了头绪。
前一个问题与<code>OpenResty</code>的code cache有关。本渣在<code>nginx</code>配置里打开了code cache：</p>

<pre><code>lua_code_cache on
</code></pre>

<p>而全局函数的使用是通过<code>nginx</code> content阶段的<code>lua</code>代码<code>require</code>加载定义这些全局函数的文件的。根据<code>OpenResty</code>官方对于code cache的说明，只有最开始运行的LuaVM才会去真正加载这些文件，执行那些定义全局函数的代码，所以这些全局函数只有在该LuaVM所在的进程里是被定义的。此后，如果请求被同一个<code>nginx</code> worker处理，则可以正常使用之前定义的全局函数；但如果请求被分到不同的worker，就会出现变量没有定义的报错。</p>

<p>至于后一个问题，本渣观察到：在第一次访问时，<code>nginx</code> worker的CPU使用量飙升，一定概率导致server端响应时间超过设置的timeout时间，从而被client端认为是超时。
后来本渣继续缩小问题的排查范围，最后将它定位到client端读取并处理策划表的代码上。由于策划表的数据量大，所以这部分代码运行起来比较耗时倒也不奇怪。而前面提到code cache打开时，被<code>require</code>的文件只加载一次，这些处理策划表的代码也只有第一次才被真正运行，所以看到的现象就是第一次的请求会经常失败了。</p>

<p>前一个问题与全局函数有关，本渣看到不少<code>OpenResty</code>前辈提到<a href="https://segmentfault.com/a/1190000004297908">要避免使用全局变量</a>：</p>

<blockquote><p>一般来说，在ngx_lua的上下文中使用Lua全局变量真的不是什么好主意：</p>

<ol>
<li><p>滥用全局变量的副作用会对并发场景产生副作用，比如当使用者把这些变量看作是本地变量的时候；</p></li>
<li><p>Lua的全局变量需要向上查找一个全局环境（只是一个Lua表），代价比较高；</p></li>
<li><p>一些Lua的全局变量引用只是拼写错误，这会导致出错很难排查。</p></li>
</ol>
</blockquote>

<p>其中一个重要原因是会对并发场景产生副作用，本渣以前入过并行程序的坑，对这一点是不能同意更多的。不过回头来看我们client端代码里的那些全局“变”量，其实都是全局常量，不仅值不会被改变，而且我们代码中只会对这些常量执行一次赋值操作（当且仅当它们被定义时），这就不存在并发的副作用问题了。对于全局变量访问开销大的问题，本渣写了个脚本，在代码文件开头对使用到的全局变量<code>local</code>化（例如<code>local XXX = require('XXX')</code>）。拼写错误引发的bug嘛，本渣之前在<a href="http://galoisplusplus.coding.me/blog/2016/03/12/svn-precommit-hook/">svn hook</a>加了检查，所以在开发过程中提交代码就能及时发现问题。逐条分析下来，倒是命名空间污染不可避免，但是我们server端和client端的代码是完全独立的，命名空间污染并不会引发什么问题。当然严格一点，还是可以把client端涉及到的全局常量全部改成<code>local</code>的，写个脚本来处理所有代码也不难。<del>但处理问题要灵活嘛，既然在具体场景里无关紧要为啥还要迷信教条多此一举？嘿嘿，本渣就是这么懒XD</del>不过本渣考虑到client端这块代码仍在持续开发新的功能，这样做会给client端码农的开发带来限制：“喂，大熊弟，乃们的代码server端也要跑的哦，以后不能用全局常量了！”“WTF！”。这种节奏就不太理想了，本渣希望server端的代码重用对client端而言是透明的，client端的大熊弟在挖坑时可以完全无视server端战斗功能的存在：“server端关我鸟事，老子该干嘛还干嘛！”所以i呢，本渣放弃了去掉全局常量的治疗，最终选择在保留client端全局常量的前提下去解决它所带来的问题。</p>

<p>本渣最后解决前面提到的两个问题的黑科技是：把<code>require</code> client端代码的部分从<code>nginx</code>的content阶段，挪到了<code>nginx</code> lua module的init阶段：</p>

<p>{% img <a href="https://cloud.githubusercontent.com/assets/2137369/15272097/77d1c09e-1a37-11e6-97ef-d9767035fc3e.png">https://cloud.githubusercontent.com/assets/2137369/15272097/77d1c09e-1a37-11e6-97ef-d9767035fc3e.png</a> %}</p>

<p>init阶段会在<code>nginx</code> master进程加载<code>nginx</code>配置时执行，之后才由master进程clone出worker进程。全局常量放在这个阶段初始化，就不会有某些worker进程没有定义全局变量的报错；处理策划表的代码放在这个阶段执行，就把CPU开销转移到加载<code>nginx</code>配置上，不会增加请求的响应时间，可谓是一石二鸟。</p>

<p>有了一个可行的prototype，接下来本渣最关心的就是性能问题了：毕竟是第一次搞<code>OpenResty</code>，没啥经验，万一上线后server不堪重负挂了呢？不过我们做server端的老司机们都对自己开的车很自信，之前从没有写过测试代码，所以单接口压力测试还得本渣这server端小白自行琢磨啦。压测工具中，<code>Apache</code>的<code>ab</code>还是挺好上手的，输出的信息也很好分析。不过本渣也犯过傻：有一次正和小伙伴吹牛逼呢，说压测出来性能特别棒，一细看就打脸了，原来都是Non-200 response&hellip;&hellip;HTTP code为啥不是200捏？原来本渣是通过写client端<code>lua</code>代码来获取POST参数的，本渣的这段代码有bug，导致POST的参数有误。后来bug改掉了，结果小伙伴一脸鄙夷：乃不是可以看server端的access log吗？干嘛非要在client端写代码获取POST参数？&hellip;&hellip;好吧，开森就好&hellip;&hellip;<code>ab</code>做压测有个问题，就是POST参数是固定的，但本渣想用不同的战斗来压测自己那块功能，需要让不同请求的POST参数各不相同。最后本渣找到了<a href="https://github.com/wg/wrk"><code>wrk</code></a>这个压测工具。<code>wrk</code>最吸引本渣的，是它支持<code>lua</code>编程，普大喜奔啊！本渣这个懒人又可以重用client端的<code>lua</code>代码了！XDD</p>

<p>压测结果有了，但要知道性能热点才好对症下药做优化啊。这个时候本渣找到了春哥写的<a href="https://github.com/OpenResty/nginx-systemtap-toolkit">SystemTap脚本</a>和<a href="https://github.com/brendangregg/FlameGraph">火焰图工具</a>，这套工具简直是profile神器啊有不有！本渣之前也折腾过cocos2d-x游戏client端的profiler，万万没想到还有内核trace这种玩法！借助春哥所介绍的On-CPU和Off-CPU火焰图，本渣改进了一些问题，例如某些不被<code>luajit</code>支持的函数，会被<code>luajit</code>解释执行，在火焰图中会有<code>lj_xxx</code>的frame。这时候可以看看这些函数能否换成<code>luajit</code>支持的函数，像本渣就发现我们client端代码里有不少用<code>pairs</code>的地方，其实应该把相应的<code>lua table</code>设计成array而非hash table，采用<code>ipairs</code>来遍历。</p>

<p>在做压测和做火焰图的时候还发生过意外，有次<code>nginx</code> worker进程占满CPU，把开发server卡死了。分析下来是因为某个testcase使client端的战斗计算一直没有达到结束条件，死循环了。这倒也不奇怪，因为我们client端的战斗按照策划大大们的需求就是支持无限回合的。那为虾米在client端不会出现战斗计算死循环导致机器卡死呢？前面提到client端有战斗计算模块和战斗表现模块，这是一个典型的producer-consumer模型：战斗计算模块是producer，生产出若干回合的战报交给战斗表现模块，然后挂起；战斗表现模块是consumer，“消费”当前尚未播放的战报，同时接收玩家的操作信息，转交给战斗计算模块进行新回合的计算。也就是说，这两者总是相继运行的。而server端不存在战斗表现模块，战斗计算模块全部算完后就返回所有回合的战报，所以server端会有卡死问题而client端木有。这个问题大家讨论下来，最后策划大大决定在server端战斗加上战斗最大回合数限制，避免死循环。现在理论上没问题了，但本渣还是不放心：万一哪天代码有个bug会触发死循环呢？一出现问题就搞个大新闻，影响到整台机器，后果很严重啊！本渣首先想到把server端拆成一般业务server和战斗server，把两者隔离开，万一战斗出现问题，其他业务仍可以正常运作；然后对战斗server的<code>nginx</code> worker进程要有资源限制，不能让它们拖垮整台机器。最后采用的大杀器也许你已经猜到了，那就是<code>Docker</code>！采用<code>Docker</code>可以很方便地用<code>namespace</code>做环境隔离、用<code>cgroups</code>做资源限制，而且<code>Docker</code> container本质上是host机的进程，不会有虚拟机的性能降级。</p>

<p>敲定了这一解决方案，接下来的挖坑工作就顺理成章分成了两块：一个是如何把我们server端<code>Docker</code>化，另一个是业务server和战斗server如何协作。前者可以被<code>Docker</code>化的有<code>OpenResty</code>的<code>nginx</code>进程、<code>MySQL</code>和<code>redis</code>实例，好在<code>OpenResty</code>、<code>MySQL</code>和<code>redis</code>都有现成的<code>Docker</code>镜像，只需要稍做修改，就可以用到我们这套server端代码上。
<code>Docker</code>的构建实在太方便了，本渣也趁着把server端<code>Docker</code>化的时候，简化搭建开发server的流程。中间为了解决自动化快速备份现有数据库数据作为开发server数据的问题，折腾了一阵，学到不少东西，不过像<code>MySQL</code> <code>InnoDB</code>等技术细节还是得找时间扫盲一下～
至于后者，由于一般业务server和战斗server采用的是同一套代码（只是<code>nginx</code>配置稍有不同，本渣折腾配置时还踩过<code>nginx</code> <code>if</code>的坑，<a href="https://moonbingbing.gitbooks.io/OpenResty-best-practices/content/ngx/if_is_evil.html">“if is evil”</a>啊！），访问的是同样的<code>MySQL</code>和<code>redis</code>实例，所以只需要考虑这样一个问题：client端在连上一般业务server后，一般业务server如何把战斗相关的请求转给战斗server来处理？<a href="https://moonbingbing.gitbooks.io/OpenResty-best-practices/content/OpenResty/how_request_http.html">《Openresty最佳实践》</a>介绍了两种最常见的HTTP接口调用方法：</p>

<ol>
<li><p><code>proxy_pass</code></p></li>
<li><p><code>cosocket</code></p></li>
</ol>


<p>这两种方式本渣都折腾过了，最后采用了<code>proxy_pass</code>的方式。因为本渣考虑到以后可能会出现战斗server集群的情况，采用<code>proxy_pass</code>可以方便在<code>nginx</code>配置的<code>upstream</code>中配置多个战斗server，做load balance，可拓展性更好。加上我们启动战斗server其实只需要创建新的<code>Docker</code>容器，这整套方案可以很容易scale上去。当然，我们游戏目前的访问量还远不需要集群去撑，考虑集群似乎有杀鸡用牛刀之嫌，不过梦想总是要有的，万一我们游戏火了呢XD</p>

<p>嗯，最近就做了这么一点微不足道的工作，本篇也没什么干货，谢谢大家！</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Nginx Tips]]></title>
    <link href="http://yszheda.github.io/blog/blog/2016/07/19/nginx-tips/"/>
    <updated>2016-07-19T11:22:00+08:00</updated>
    <id>http://yszheda.github.io/blog/blog/2016/07/19/nginx-tips</id>
    <content type="html"><![CDATA[<p>最近在做server端开发，需要熟悉nginx，本渣也就在这里记录下自己遇到的一些问题。其实都比较小白，纯粹当作自我扫盲啦XD 本文将不定期更新。</p>

<h1>nginx: [emerg] bind() to \&lt;ip>:\&lt;port> failed (98: Address already in use)</h1>

<pre><code>nginx: [emerg] bind() to &lt;ip&gt;:&lt;port&gt; failed (98: Address already in use)
</code></pre>

<p>端口被占用，可以用查看使用文件或socket的命令<code>fuser</code>来杀掉占用端口的进程：</p>

<pre><code>$ sudo fuser -k &lt;port&gt;/tcp
</code></pre>

<p>此外，如果使用IPv6还可能出现如下报错：</p>

<pre><code>nginx: [emerg] bind() to [::]:&lt;port&gt; failed (98: Address already in use)
</code></pre>

<p>这是由于<code>nginx</code>配置中有<code>listen &lt;port&gt;;</code>，又有<code>listen [::]:&lt;port&gt;;</code>所致。
根据<a href="http://nginx.org/en/docs/http/ngx_http_core_module.html#listen">nginx文档</a>的描述：</p>

<blockquote><p>By default, nginx will look up both IPv4 and IPv6 addresses while resolving.</p></blockquote>

<p>也就是说，<code>listen [::]:&lt;port&gt;;</code>会同时监听IPv4和IPv6的流量，所以<code>listen &lt;port&gt;;</code>是重复配置，将它删掉即可。
如果只想使用IPv6可以采用：</p>

<pre><code>listen [::]:&lt;port&gt; ipv6only=on;
</code></pre>

<h2>参考</h2>

<p><a href="http://stackoverflow.com/questions/14972792/nginx-nginx-emerg-bind-to-80-failed-98-address-already-in-use">(SOF) nginx - nginx: [emerg] bind() to [::]:80 failed (98: Address already in use)</a></p>

<h1>worker_connections are more than open file resource limit: 1024</h1>

<p>这是因为nginx worker的用户打开的文件超过上限。</p>

<p>如果nginx配置中有<code>worker_rlimit_nofile</code>参数，则打开的文件数量上限由<code>worker_rlimit_nofile</code>决定（nofile=number of open files）。
那么<code>worker_rlimit_nofile</code>应该配多少呢？</p>

<p>在nginx配置的core module中找到<code>worker_processes</code>数量：</p>

<pre><code>worker_processes  4;
</code></pre>

<p>在event module中找到<code>worker_connections</code>数量：</p>

<pre><code>events {
    worker_connections  1024;
}
</code></pre>

<p>那么最大总连接数是<code>worker_connections * worker_processes</code>，每个active connection都会占用一个文件描述符（file descriptor），所以<code>worker_rlimit_nofile</code>最好大于<code>worker_connections * worker_processes</code>。</p>

<h2>参考</h2>

<p><a href="http://nginx.org/en/docs/ngx_core_module.html#worker_rlimit_nofile">nginx worker_rlimit_nofile文档</a></p>

<p><a href="http://serverfault.com/questions/208916/understanding-max-file-descriptors-for-linux-and-nginx-and-best-value-for-worke">(SOF) understanding max file descriptors for linux and nginx, and best value for worker_rlimit_nofile</a></p>

<p><a href="http://serverfault.com/questions/209014/how-can-i-observe-what-nginx-is-doing-to-solve-1024-worker-connections-are-n">(SOF) How can I observe what nginx is doing? (to solve: “1024 worker_connections are not enough”)</a></p>

<p>如果nginx配置中没有<code>worker_rlimit_nofile</code>参数，则采用系统默认的打开的文件数量上限。那么如何查看并修改这一上限呢？</p>

<p>首先在nginx配置的core module中找到nginx worker进程的用户：</p>

<pre><code>user nginx;
</code></pre>

<p>在终端登入这一用户：</p>

<pre><code>$ sudo su - nginx
</code></pre>

<p>查看文件描述符的硬上限：</p>

<pre><code>$ ulimit -Hn
</code></pre>

<p>查看文件描述符的软上限：</p>

<pre><code>$ ulimit -Sn
</code></pre>

<p>这里硬上限是严格不能超过的上限，不能增加。软上限属于警告性质的上限，可以调高，但也不能超过硬上限。</p>

<p>在<code>/etc/sysctl.conf</code>中修改下述数值：</p>

<pre><code>fs.file-max = 65536
</code></pre>

<p>使用以下命令加载新的配置：</p>

<pre><code>$ sysctl -p
</code></pre>

<p>检查是否已更新：</p>

<pre><code>$ cat /proc/sys/fs/file-max
</code></pre>

<p>一些资料提到修改<code>/etc/security/limits.conf</code>中nofile的软上限和硬上限：</p>

<pre><code>* soft     nofile         65535
* hard     nofile         65535
root soft     nofile         65535
root hard     nofile         65535
</code></pre>

<p>这种方式至少需要nginx worker进程重启才能生效。</p>

<h2>参考</h2>

<p><a href="http://ss64.com/bash/ulimit.html">ulimit manual</a></p>

<p><a href="http://www.ibm.com/developerworks/cn/linux/l-cn-ulimit/index.html">通过 ulimit 改善系统性能</a></p>

<p><a href="http://stackoverflow.com/questions/3107476/what-does-soft-hard-nofile-mean-on-linux">What does “soft/hard nofile” mean on Linux</a></p>

<p><a href="http://unix.stackexchange.com/questions/29577/ulimit-difference-between-hard-and-soft-limits">ulimit: difference between hard and soft limits</a></p>

<p><a href="http://ss64.com/bash/limits.conf.html">limits.conf manual</a></p>

<p><a href="http://www.cyberciti.biz/faq/making-changes-to-proc-filesystem-permanently/">Making changes to /proc filesystem permanently</a></p>

<p><a href="http://serverfault.com/questions/640976/nginx-ulimit-worker-connections-exceed-open-file-resource-limit-1024">nginx uLimit &lsquo;worker_connections exceed open file resource limit: 1024&rsquo;</a></p>

<p><a href="http://unix.stackexchange.com/questions/108603/do-changes-in-etc-security-limits-conf-require-a-reboot">do changes in /etc/security/limits.conf require a reboot?</a></p>

<p><a href="http://serverfault.com/questions/165316/how-to-configure-linux-file-descriptor-limit-with-fs-file-max-and-ulimit">How to configure linux file descriptor limit with fs.file-max and ulimit</a></p>

<p><a href="http://stackoverflow.com/questions/21515463/how-to-increase-maximum-file-open-limit-ulimit-in-ubuntu">How to increase maximum file open limit (ulimit) in Ubuntu?</a></p>

<p><a href="http://www.cyberciti.biz/faq/linux-unix-nginx-too-many-open-files/">Nginx: 24: Too Many Open Files Error And Solution</a></p>

<h1>an upstream response is buffered to a temporary file</h1>

<h1>proxy_temp failed (13: Permission denied) while reading upstream</h1>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[用ab和wrk做压力测试]]></title>
    <link href="http://yszheda.github.io/blog/blog/2016/07/07/server-press-test-tips/"/>
    <updated>2016-07-07T11:22:00+08:00</updated>
    <id>http://yszheda.github.io/blog/blog/2016/07/07/server-press-test-tips</id>
    <content type="html"><![CDATA[<p>之前一直在做cocos2d-x手游客户端开发，最近被组织上安排去做服务器开发了。虽然一开始接触<code>OpenResty</code>，遇到不少问题，但由于本渣重用了大量以前的代码，倒也很快就完成了一个可以正常运作的版本。只是本渣毕竟是新手，所做的功能也没有前人踩坑的经验，对自己代码的性能不放心，所以这段时间也在折腾压力测试，这次就来分享一些做压测的tips。</p>

<p>首先，<code>Apache</code>的<code>ab</code>可以很方便地产生大量（并发）的同一请求，<code>ab</code>上手也很容易，是做简单压测的首选工具之一。</p>

<p>使用<code>ab</code>需要注意几个选项：</p>

<ul>
<li><code>-p</code>指定POST参数，与<code>curl</code>不同，<code>ab</code>的POST参数选项必须指定一个文件。</li>
</ul>


<pre><code>       -p POST-file
              File containing data to POST. Remember to also set -T.
</code></pre>

<ul>
<li><code>-T</code>和<code>-H</code>指定HTTP Header（前者是<code>Content-type</code>）:</li>
</ul>


<pre><code>       -T content-type
              Content-type  header  to  use  for  POST/PUT  data,  eg.  application/x-www-form-urlencoded.  Default is
              text/plain.

       -H custom-header
              Append extra headers to the request. The argument is typically in the form of a valid header line,  con‐
              taining a colon-separated field-value pair (i.e., "Accept-Encoding: zip/zop;8bit").
</code></pre>

<p>像本渣压测时就用到了如下参数：</p>

<pre><code>-H 'Accept-Encoding: gzip' -T 'application/x-www-form-urlencoded'
</code></pre>

<p>之前manual提到POST必须指定<code>-T</code>参数，但如果少了前面的<code>-H</code>参数，测出来的数据会和实际情况有偏差。指定<code>ab</code>的这些参数最好是和实际的客户端的HTTP header保持一致，个人建议采用<code>tcpdump</code>或<code>Wireshark</code>等工具来抓取实际的客户端访问服务器的HTTP请求。</p>

<ul>
<li><code>-s</code>指定timeout时间，这个参数也最好与实际客户端的设置保持一致。</li>
</ul>


<pre><code>       -s timeout
              Maximum number of seconds to wait before the socket times out. Default is 30 seconds. Available in 2.4.4
              and later.
</code></pre>

<ul>
<li>需要特别注意的是，<code>ab</code>默认不启用HTTP Keep-Alive，需要使用<code>-k</code>开启这一特性：</li>
</ul>


<pre><code>       -k     Enable  the  HTTP KeepAlive feature, i.e., perform multiple requests within one HTTP session. Default is
              no KeepAlive.
</code></pre>

<p>关于HTTP Keep-Alive，下面有两张直观的图说得很明白：</p>

<p>不采用HTTP Keep-Alive，请求某一网页的html和css会通过不同的TCP连接去完成：</p>

<p>{% img <a href="https://hpbn.co/assets/diagrams/84cf0f29175e4b11a2343e73105637c5.svg">https://hpbn.co/assets/diagrams/84cf0f29175e4b11a2343e73105637c5.svg</a> %}</p>

<p>同样的场景，采用HTTP Keep-Alive，就可以在同一TCP连接中请求尽可能多的资源，从而避免建立TCP连接的overhead：</p>

<p>{% img <a href="https://hpbn.co/assets/diagrams/cf6057a54f005a288d832d293965ee0d.svg">https://hpbn.co/assets/diagrams/cf6057a54f005a288d832d293965ee0d.svg</a> %}</p>

<p>以上两张图是从Ilya Grigorik的<a href="https://hpbn.co/">High Performance Browser Networking</a>引用过来的，如果你对HTTP Keep-Alive不熟悉的话，可以参考下这本书。</p>

<p>PS. 这里为了不把HTTP Keep-Alive和TCP keepalive混淆起来，本渣就不随Grigorik写做keepalive了。</p>

<ul>
<li>还有另一个需要特别注意的地方，由于<code>ab</code>发起的请求都是一模一样的，所以<code>ab</code>认为服务器的返回也应该完全相同才对。如果服务器对相同请求的处理结果不同——像本渣做的功能恰好就是这种情况——需要再指定<code>-l</code>选项：</li>
</ul>


<pre><code>       -l     Do not report errors if the length of the responses is not constant. This  can  be  useful  for  dynamic
              pages. Available in 2.4.7 and later.
</code></pre>

<p>前面提到<code>ab</code>所产生的请求都是一样的，如果我们想用不同的testcase来做压测呢？这时候<code>ab</code>就无能为力了，好在还有其他强大的压测工具，例如<a href="https://github.com/wg/wrk">wrk</a>。<code>wrk</code>支持<code>lua</code>编程，可以通过override<code>request</code>、<code>response</code>的全局函数来指定请求和响应的处理逻辑，这给本渣做压测带来不少便利，因为本渣之前不就是做客户端开发嘛，现在可以直接重用客户端的代码了XD</p>

<p>关于<code>ab</code>和<code>wrk</code>的具体用法和细节请参考下面的链接，本渣这里就不赘述了，毕竟把别人提过的东西又重复一遍就没什么意思了<del>其实就是懒癌XD</del></p>

<h1>参考资料</h1>

<ul>
<li><p>阿里云这篇文章<a href="https://yq.aliyun.com/articles/35251">使用ab和wrk对OSS进行benchmark测试</a>挺好的，推荐一看</p></li>
<li><p>耗子叔的这篇博文也值得一看：<a href="http://coolshell.cn/articles/17381.html">性能测试应该怎么做？</a>。在做压测之前应当考虑清楚，设计适当的testcase。</p></li>
<li><p><code>ab</code>的使用可以参考：</p>

<ul>
<li><p><a href="http://leepiao.blog.163.com/blog/static/485031302010234352282/">Apache ab 压力测试</a></p></li>
<li><p><a href="http://mo2g.com/view/50/">使用Apache Benchmark做压力测试遇上的5个常见问题</a></p></li>
<li><p><a href="http://www.cnblogs.com/bandbandme/p/3680542.html">linux下ab网站压力测试命令 - post请求</a></p></li>
</ul>
</li>
<li><p><code>wrk</code>的使用可以参考：</p>

<ul>
<li><p><a href="http://charmyin.github.io/informationtechnology/2014/08/11/multiple-file-upload-express/">WRK - A HTTP benchmarking tool</a></p></li>
<li><p><a href="http://czerasz.com/2015/07/19/wrk-http-benchmarking-tool-example/">WRK the HTTP benchmarking tool - Advanced Example</a></p></li>
<li><p><a href="https://blog.satikey.com/p/5768.html">wrk — 小巧轻盈的 http 性能测试工具</a></p></li>
</ul>
</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[svn pre-commit hook两三事]]></title>
    <link href="http://yszheda.github.io/blog/blog/2016/03/12/svn-precommit-hook/"/>
    <updated>2016-03-12T10:26:00+08:00</updated>
    <id>http://yszheda.github.io/blog/blog/2016/03/12/svn-precommit-hook</id>
    <content type="html"><![CDATA[<p>说起折腾svn hook这件事还是在去年年底。我厂向来木有Code Review等Quality Assurance流程，全赖老司机们各种强力输出。而当时我们项目的不少老司机要么去了其他部门要么离职了，新来的小鲜肉码农们似乎对Version Control一无所知。别的不说，单是commit不写comment，便让大家头疼不已，每次在merge时都得额外花不少时间来搞清楚commit的具体内容。虽然我自从投奔<code>git</code>阵营后基本都是用<code>git svn</code>，对<code>svn</code>生疏已久，但觉得加个<code>svn</code>提交限制应非难事，所以便额外花了点时间写了个pre-commit hook，对commit的comment中的非空白字符做计数，少于一定字数的不让提交。万万没想到，当时让SA大大部署上<code>svn</code>服务器后，就有人commit了一个“再试一下”orz&hellip;当时我的内心是崩溃的&hellip;在推上围脖上吐槽后不久，众位大神各种支招，例如巨硬的泉哥说再搞个语义分析器666&hellip;不过最受用的还是根爷所提到的用<code>cpplint</code>检查代码是否符合编码规范、是否能够编译通过。恰好那段时间小鲜肉们提交了一些带有语法错误的lua代码，偶们又木有review制度，结果不写程序的策划大大们<code>svn up</code>下来后——「什么鬼？肿么不能运行了？！好拙计啊！AAA，快来看bug啊！BBB，SOS！」——导致别人不得不停下手头的活、额外花时间排查。所以我便在pre-commit hook里用<code>luac</code>检查语法错误的代码，把这种坑队友的事扼杀在摇篮里。虽然不及<code>cpplint</code>那么强大，但也基本够用了。最近一次改这个脚本是因为前段时间有个小鲜肉做了一张4096x4096的图集，而cocos2d-x文档里写得清清楚楚，大多数手机所支持的最大纹理尺寸其实只有2048x2048&hellip;卧槽，干得漂亮啊，一上线就造成了不少crash&hellip;木有review制度好可啪，在发现这个问题之前其他人一直毫不知情&hellip;所以我还是干脆在svn hook里再加个限制吧～</p>

<p>好了，不碎碎念了，这便是我折腾的svn hook，主要做了这么几项功能：</p>

<ul>
<li><p>commit message非空白长度检查</p></li>
<li><p>lua语法检查</p></li>
<li><p>禁止添加文件名带空格的文件</p></li>
<li><p>禁止被配在<code>PROHIBITED_FILES</code>的文件被修改</p></li>
<li><p>确保图片尺寸小于2048x2048</p></li>
</ul>


<pre><code>#!/bin/sh

# PRE-COMMIT HOOK
#
# The pre-commit hook is invoked before a Subversion txn is
# committed.  Subversion runs this hook by invoking a program
# (script, executable, binary, etc.) named 'pre-commit' (for which
# this file is a template), with the following ordered arguments:
#
#   [1] REPOS-PATH   (the path to this repository)
#   [2] TXN-NAME     (the name of the txn about to be committed)
#
#   [STDIN] LOCK-TOKENS ** the lock tokens are passed via STDIN.
#
#   If STDIN contains the line "LOCK-TOKENS:\n" (the "\n" denotes a
#   single newline), the lines following it are the lock tokens for
#   this commit.  The end of the list is marked by a line containing
#   only a newline character.
#
#   Each lock token line consists of a URI-escaped path, followed
#   by the separator character '|', followed by the lock token string,
#   followed by a newline.
#
# The default working directory for the invocation is undefined, so
# the program should set one explicitly if it cares.
#
# If the hook program exits with success, the txn is committed; but
# if it exits with failure (non-zero), the txn is aborted, no commit
# takes place, and STDERR is returned to the client.   The hook
# program can use the 'svnlook' utility to help it examine the txn.
#
# On a Unix system, the normal procedure is to have 'pre-commit'
# invoke other programs to do the real work, though it may do the
# work itself too.
#
#   ***  NOTE: THE HOOK PROGRAM MUST NOT MODIFY THE TXN, EXCEPT  ***
#   ***  FOR REVISION PROPERTIES (like svn:log or svn:author).   ***
#
#   This is why we recommend using the read-only 'svnlook' utility.
#   In the future, Subversion may enforce the rule that pre-commit
#   hooks should not modify the versioned data in txns, or else come
#   up with a mechanism to make it safe to do so (by informing the
#   committing client of the changes).  However, right now neither
#   mechanism is implemented, so hook writers just have to be careful.
#
# Note that 'pre-commit' must be executable by the user(s) who will
# invoke it (typically the user httpd runs as), and that user must
# have filesystem-level permission to access the repository.
#
# On a Windows system, you should name the hook program
# 'pre-commit.bat' or 'pre-commit.exe',
# but the basic idea is the same.
#
# The hook program typically does not inherit the environment of
# its parent process.  For example, a common problem is for the
# PATH environment variable to not be set to its usual value, so
# that subprograms fail to launch unless invoked via absolute path.
# If you're having unexpected problems with a hook program, the
# culprit may be unusual (or missing) environment variables.
# 
# Here is an example hook script, for a Unix /bin/sh interpreter.
# For more examples and pre-written hooks, see those in
# the Subversion repository at
# http://svn.apache.org/repos/asf/subversion/trunk/tools/hook-scripts/ and
# http://svn.apache.org/repos/asf/subversion/trunk/contrib/hook-scripts/

LOG="/tmp/svn.log"
touch ${LOG}

REPOS="$1"
TXN="$2"
echo "REPOS: $REPOS" &gt; ${LOG}
echo "TXN: $TXN" &gt;&gt; ${LOG}

SVNLOOK=""

# lua compiler
LUAC=""
# lua file extension
LUA_EXT="lua"
# png file extension
PNG_EXT="png"

MSG_MIN_CHAR_NUM=3

MAX_PNG_SIZE=2048

PROHIBITED_FILES=(
)

TMP_DIR="/tmp/svn"
if [[ -d ${TMP_DIR} ]]; then
    rm -r ${TMP_DIR}
fi
mkdir -p ${TMP_DIR}

function check_lua_syntax {
local lua_file=$1
echo `${LUAC} ${lua_file} 2&gt;&amp;1`
}

function create_file {
local file_name=$1
# Create tmp file and copy content
tmp_file="${TMP_DIR}/${file_name}"
mkdir -p "$(dirname "${tmp_file}")" &amp;&amp; touch "${tmp_file}"
${SVNLOOK} cat -t "${TXN}" "${REPOS}" "${file_name}" &gt; ${tmp_file}
}

# Make sure that the log message contains some text.
commit_msg=`$SVNLOOK log -t "$TXN" "$REPOS" | sed 's/[[:space:]]//g'`
echo ${commit_msg} &gt;&gt; ${LOG}
if [[ `echo ${commit_msg} | wc -c` -lt ${MSG_MIN_CHAR_NUM} ]]; then
    echo "Please write a meaningful comment when committing" 1&gt;&amp;2
    exit 1
fi

changed_info_str=`${SVNLOOK} changed -t "${TXN}" "${REPOS}"`
IFS=$'\n' read -rd '' -a changed_infos &lt;&lt;&lt;"${changed_info_str}"

lua_error_msg=""
png_error_msg=""
for changed_info in "${changed_infos[@]}"; do
    # Prevent commiting file that contains space in its filename
    echo ${changed_info} &gt;&gt; ${LOG}
    operation=`echo ${changed_info} | awk '{print $1}'`
    if [[ ${operation} = "A" ]] &amp;&amp; [[ `echo ${changed_info} | awk '{print NF}'` -gt 2 ]]; then
        echo "Please do not commit file that contains space in its filename!" 1&gt;&amp;2
        exit 1
    fi
    file_name=`echo ${changed_info} | awk '{print $2}'`
    echo "operation: ${operation}, file: ${file_name}, ext: ${ext}" &gt;&gt; ${LOG}

    # Check prohibit-commit files
    for prohibited_file in ${PROHIBITED_FILES[@]}; do
        if [[ ${file_name} = ${prohibited_file} ]]; then
            echo "${file_name} is not allowed to be changed!" 1&gt;&amp;2
            exit 1
        fi
    done

    ext=`echo ${file_name} | awk -F"." '{print $NF}'`

    if [[ ${operation} = "U" ]] || [[ ${operation} = "A" ]]; then
        tmp_file="${TMP_DIR}/${file_name}"

        # Check lua syntax
        if [[ ${ext} = ${LUA_EXT} ]]; then
            echo "Check syntax of ${tmp_file}" &gt;&gt; ${LOG}
            create_file ${file_name}
            error_msg=`check_lua_syntax ${tmp_file}`
            if [[ `echo ${error_msg} | sed 's/\n//g'` != "" ]]; then
                lua_error_msg="${lua_error_msg}\n${error_msg}"
            fi
        fi

        # Check file size
        if [[ ${ext} = ${PNG_EXT} ]]; then
            create_file ${file_name}
            png_info=`file ${tmp_file} | sed 's/,//g'`
            png_width=`echo ${png_info} | awk '{print $5}' | bc`
            png_height=`echo ${png_info} | awk '{print $7}' | bc`
            if [[ ${png_width} -gt ${MAX_PNG_SIZE} ]] || [[ ${png_height} -gt ${MAX_PNG_SIZE} ]]; then
                png_error_msg="${png_error_msg}\n${file_name} is too large: ${png_width} x ${png_height}"
            fi
        fi
    fi
done

rm -r ${TMP_DIR}

if [[ ${lua_error_msg} != "" ]] || [[ ${png_error_msg} != "" ]]; then
    if [[ ${lua_error_msg} != "" ]]; then
        echo "lua error: ${lua_error_msg}" &gt;&gt; ${LOG}
        echo "Please fix the error in your lua program:${lua_error_msg}" 1&gt;&amp;2
    fi

    if [[ ${png_error_msg} != "" ]]; then
        echo "png error: ${png_error_msg}" &gt;&gt; ${LOG}
        echo "Please do not commit pictures which are larger than 2048 x 2048:${png_error_msg}" 1&gt;&amp;2
    fi

    exit 1
fi

# Check that the author of this commit has the rights to perform
# the commit on the files and directories being modified.
# commit-access-control.pl "$REPOS" "$TXN" commit-access-control.cfg || exit 1

# All checks passed, so allow the commit.
exit 0
</code></pre>

<p>PS. 聪哥说作为一位开发去搞svn hook怕被公司的其他开发喷越权管了运维的事，我厂倒是不存在这种问题的——人少活多时间紧，啥活都得揽啊，例如我一位舍友兼同事的大神以前开发手游可是客户端、服务器、策划、切图全都一人搞定，就差自己出美术图和特效了。最近我也在像运维一样写脚本自动化处理某些项目文件，发现我们开发各种混乱啊有木有！例如路径带空格，我的一些<code>awk</code>脚本就雪崩了——我在以上的<code>hook</code>脚本里也有同样的问题，其实把列计数方式改一下，例如<code>$7</code>改成<code>${NF-4}</code>，可以避免这种问题——而且还要把带空格的路径用<code>sed</code>替换成转义后的字符串。不过这种情况还算好的，还有些人用的单词有拼写错误，要是全错了倒也罢了，脚本hold得住，问题是有的对有的错&hellip;偶只能弃疗了&hellip;</p>

<h1>后记</h1>

<p>由于我们lua代码中存在不少没声明<code>local</code>而变成全局变量的bug，于是我把Openresty作者春哥的<code>lua-releng</code>工具也加进<code>hook</code>里做全局变量检查了。具体可以看<a href="https://gist.github.com/yszheda/6125a32e37834cc8ab75">这个gist</a>。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[小记Linux/UNIX下错误权限恢复]]></title>
    <link href="http://yszheda.github.io/blog/blog/2016/02/16/how-to-fix-wrong-chmod-777-problem/"/>
    <updated>2016-02-16T23:48:00+08:00</updated>
    <id>http://yszheda.github.io/blog/blog/2016/02/16/how-to-fix-wrong-chmod-777-problem</id>
    <content type="html"><![CDATA[<p>继我<a href="http://galoisplusplus.coding.me/blog/2016/02/02/how-to-restore-deleted-file-in-linux/">不久前犯二</a>之后，今天一位同事小伙伴也逗逼了，给<code>/etc/sudoers</code>加了777权限&hellip;6666结果<code>sudo</code>就悲剧了：
<code>
sudo: /etc/sudoers is mode 0777, should be 0440
sudo: no valid sudoers sources found, quitting
</code></p>

<p>我一开始还想用<code>pkexec</code>恢复：
<code>
pkexec chmod 0440 /etc/sudoers
</code>
不料机器上木有装<code>PolicyKit</code>&hellip;</p>

<p>后来小伙伴找SA要root密码搞定了。不过这倒勾起了我的好奇心：这种悲剧除了<code>pkexec</code>、除了拿到root权限（包括重启系统进恢复模式）执行复原操作，难道只能GG了么？后来查到了<a href="https://gist.github.com/syxc/2822948">《sudo chmod 777 / 惨剧修复简单步骤》</a>这篇文章，发现获取和设置UNIX文件Access Control List (ACL)的命令<code>getacl</code>/<code>setacl</code>还能有这种妙用，这便是我想找的另一套解决方案了。</p>

<p>不过，以后还是装上<code>PolicyKit</code>，以防不测吧&hellip;</p>

<h1>参考资料</h1>

<p><a href="http://superuser.com/questions/300743/sudo-chmod-r-777">http://superuser.com/questions/300743/sudo-chmod-r-777</a></p>

<p><a href="http://unix.stackexchange.com/questions/12998/wrongly-set-chmod-777-problems">Wrongly set chmod / 777. Problems?</a></p>

<p><a href="http://askubuntu.com/questions/50704/sudo-error-is-mode-0777-should-be-0440">sudo error, is mode 0777, should be 0440</a></p>

<p><a href="http://stackoverflow.com/questions/16682297/getting-message-sudo-must-be-setuid-root-but-sudo-is-already-owned-by-root">Getting message “sudo: must be setuid root”, but sudo IS already owned by root</a></p>
]]></content>
  </entry>
  
</feed>
